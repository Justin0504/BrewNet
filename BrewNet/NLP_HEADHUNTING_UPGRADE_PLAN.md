# NLP Headhunting ç³»ç»Ÿå‡çº§æ–¹æ¡ˆ

> **ç‰ˆæœ¬**: 2.0  
> **åˆ›å»ºæ—¥æœŸ**: 2024-11-21  
> **è´Ÿè´£äºº**: BrewNet Team Heady  
> **çŠ¶æ€**: ğŸš§ å®æ–½ä¸­

---

## å‡çº§èƒŒæ™¯

### å½“å‰é—®é¢˜

#### 1. å¬å›æ± ï¼ˆRecallï¼‰ä¸¥é‡å—é™
- ä»…åœ¨æ¨èç³»ç»Ÿç»™å‡ºçš„ **60ä¸ªå€™é€‰äºº** ä¸­ç­›é€‰
- å¦‚æœè¿™60äººé‡Œæ²¡æœ‰"Stanford Alumni"ï¼ŒNLPç®—æ³•å†å¼ºä¹Ÿæœä¸åˆ°
- **å‡†ç¡®ç‡ä¸Šé™è¢«é”æ­»**

#### 2. è¯­ä¹‰é¸¿æ²Ÿï¼ˆSemantic Gapï¼‰
- å®Œå…¨ä¾èµ–å…³é”®è¯ç¡¬åŒ¹é…ï¼ˆExact Matchï¼‰
- æ— æ³•ç†è§£è¯­ä¹‰æ¦‚å¿µï¼ˆå¦‚ "Top Tech Firm"ï¼‰
- æ— æ³•è¯†åˆ«ç¼©å†™ï¼ˆå¦‚ "PM" = "Product Manager"ï¼‰
- æ— æ³•å¤„ç†åŒä¹‰è¯ï¼ˆ"Mentor" vs "Coach"ï¼‰

### å‡çº§ç›®æ ‡

| æŒ‡æ ‡ | å½“å‰å€¼ | ç›®æ ‡å€¼ | æå‡ |
|-----|--------|--------|------|
| å¬å›æ± å¤§å° | 60äºº | 200-500äºº | 3-8å€ |
| å¬å›å‡†ç¡®ç‡ | ~60% | >85% | +25% |
| è¯­ä¹‰ç†è§£ | 0% | >70% | è´¨çš„é£è·ƒ |
| å“åº”æ—¶é—´ | 1000ms | <800ms | -20% |

---

## å‡çº§æ–¹æ¡ˆæ¦‚è§ˆ

### å››å¤§ç»´åº¦

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NLP Headhunting 2.0                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  1ï¸âƒ£ æ¶æ„å±‚ï¼šä¸¤é˜¶æ®µæ£€ç´¢                                        â”‚
â”‚     å¬å›æ± : 60äºº â†’ 200-500äºº                                 â”‚
â”‚     æ–¹æ³•: å€’æ’ç´¢å¼• + å‘é‡æ£€ç´¢                                  â”‚
â”‚                                                              â”‚
â”‚  2ï¸âƒ£ NLPå±‚ï¼šæ„å›¾ç†è§£                                           â”‚
â”‚     å…³é”®è¯åŒ¹é… â†’ ç»“æ„åŒ–è§£æ                                    â”‚
â”‚     æ–¹æ³•: NER + åŒä¹‰è¯ + Query Expansion                      â”‚
â”‚                                                              â”‚
â”‚  3ï¸âƒ£ ç‰¹å¾å·¥ç¨‹ï¼šç»†ç²’åº¦ç‰¹å¾                                       â”‚
â”‚     ä¸€é”…ä¹±ç‚– â†’ åˆ†åŒºåŠ æƒ                                        â”‚
â”‚     æ–¹æ³•: Field-Aware + Concept Tagging                      â”‚
â”‚                                                              â”‚
â”‚  4ï¸âƒ£ è¯„åˆ†ç®—æ³•ï¼šåŠ¨æ€åŠ æƒ                                         â”‚
â”‚     çº¿æ€§åŠ åˆ† â†’ BM25 + è½¯åŒ¹é…                                  â”‚
â”‚     æ–¹æ³•: TF-IDF + Gaussian Decay                           â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Phase 1: æ¶æ„å±‚å‡çº§

### 1.1 ä¸¤é˜¶æ®µæ£€ç´¢æ¶æ„

#### å½“å‰æ¶æ„
```
User Query
    â†“
RecommendationService (60äºº)
    â†“
æœ¬åœ°NLPè¿‡æ»¤
    â†“
Top 5
```

#### æ–°æ¶æ„
```
User Query
    â†“
[ç²—æ’] æ•°æ®åº“å¬å› (200-500äºº)
    â”œâ”€ å…¨æ–‡ç´¢å¼• (PostgreSQL tsvector)
    â”œâ”€ å€’æ’ç´¢å¼• (Trigram)
    â””â”€ å‘é‡æ£€ç´¢ (pgvector) [å¯é€‰]
    â†“
[ç²¾æ’] æœ¬åœ°NLPæ‰“åˆ†
    â”œâ”€ ç»“æ„åŒ–è§£æ
    â”œâ”€ è¯­ä¹‰åŒ¹é…
    â””â”€ åŠ¨æ€åŠ æƒ
    â†“
Top 5
```

### 1.2 æ•°æ®åº“å±‚æ”¹é€ 

#### SQL Schema æ‰©å±•

```sql
-- 1. æ·»åŠ å…¨æ–‡æœç´¢å­—æ®µ
ALTER TABLE user_features 
ADD COLUMN searchable_text_tsv tsvector;

-- 2. åˆ›å»ºå…¨æ–‡ç´¢å¼•
CREATE INDEX idx_searchable_text_gin 
ON user_features 
USING gin(searchable_text_tsv);

-- 3. åˆ›å»º Trigram ç´¢å¼•ï¼ˆæ¨¡ç³Šæœç´¢ï¼‰
CREATE EXTENSION IF NOT EXISTS pg_trgm;
CREATE INDEX idx_searchable_text_trgm 
ON user_features 
USING gin(searchable_text gin_trgm_ops);

-- 4. æ›´æ–°è§¦å‘å™¨ï¼ˆè‡ªåŠ¨ç»´æŠ¤æœç´¢æ–‡æœ¬ï¼‰
CREATE OR REPLACE FUNCTION update_searchable_text()
RETURNS TRIGGER AS $$
BEGIN
    NEW.searchable_text_tsv := 
        setweight(to_tsvector('english', COALESCE(NEW.location, '')), 'A') ||
        setweight(to_tsvector('english', COALESCE(NEW.industry, '')), 'A') ||
        setweight(to_tsvector('english', COALESCE(NEW.career_stage, '')), 'B') ||
        setweight(to_tsvector('english', 
            COALESCE(array_to_string(NEW.skills, ' '), '')), 'B');
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trigger_update_searchable_text
BEFORE INSERT OR UPDATE ON user_features
FOR EACH ROW EXECUTE FUNCTION update_searchable_text();
```

#### å‘é‡æ£€ç´¢æ‰©å±•ï¼ˆè¿›é˜¶ï¼‰

```sql
-- 1. å®‰è£… pgvector æ‰©å±•
CREATE EXTENSION IF NOT EXISTS vector;

-- 2. æ·»åŠ å‘é‡åˆ—
ALTER TABLE user_features 
ADD COLUMN profile_embedding vector(768);  -- 768ç»´å‘é‡

-- 3. åˆ›å»ºå‘é‡ç´¢å¼•
CREATE INDEX idx_profile_embedding_ivfflat 
ON user_features 
USING ivfflat (profile_embedding vector_cosine_ops)
WITH (lists = 100);
```

### 1.3 Swift å¬å›å±‚å®ç°

**æ–°æ–‡ä»¶**: `BrewNet/HeadhuntingRecallService.swift`

```swift
import Foundation

class HeadhuntingRecallService {
    private let supabaseService = SupabaseService.shared
    
    /// ä¸¤é˜¶æ®µå¬å›
    func recall(
        query: String,
        currentUserId: String,
        limit: Int = 200
    ) async throws -> [BrewNetProfile] {
        // 1. è§£ææŸ¥è¯¢æ„å›¾
        let parsedQuery = parseQuery(query)
        
        // 2. æ„å»ºæ•°æ®åº“æŸ¥è¯¢
        var candidates: [BrewNetProfile] = []
        
        // ç­–ç•¥A: å…¨æ–‡æœç´¢å¬å›
        let textRecall = try await fullTextSearch(
            query: parsedQuery.rawText,
            limit: limit
        )
        candidates.append(contentsOf: textRecall)
        
        // ç­–ç•¥B: ç»“æ„åŒ–å¬å›ï¼ˆå¦‚æœæœ‰æ˜ç¡®å­—æ®µï¼‰
        if let school = parsedQuery.school {
            let schoolRecall = try await searchBySchool(
                school: school,
                limit: 100
            )
            candidates.append(contentsOf: schoolRecall)
        }
        
        if let company = parsedQuery.company {
            let companyRecall = try await searchByCompany(
                company: company,
                limit: 100
            )
            candidates.append(contentsOf: companyRecall)
        }
        
        // 3. å»é‡ï¼ˆåŒä¸€ç”¨æˆ·å¯èƒ½é€šè¿‡å¤šä¸ªç­–ç•¥å¬å›ï¼‰
        let uniqueCandidates = Array(Set(candidates.map { $0.userId }))
            .compactMap { userId in
                candidates.first { $0.userId == userId }
            }
        
        // 4. æ’é™¤å·²è¿æ¥/å·²æ‹’ç»çš„ç”¨æˆ·
        let filtered = try await filterExcluded(
            candidates: uniqueCandidates,
            currentUserId: currentUserId
        )
        
        print("ğŸ“Š Recall stats:")
        print("  - Text search: \(textRecall.count)")
        print("  - School filter: \(parsedQuery.school != nil ? "Yes" : "No")")
        print("  - Company filter: \(parsedQuery.company != nil ? "Yes" : "No")")
        print("  - Total unique: \(uniqueCandidates.count)")
        print("  - After filtering: \(filtered.count)")
        
        return Array(filtered.prefix(limit))
    }
    
    /// å…¨æ–‡æœç´¢
    private func fullTextSearch(
        query: String,
        limit: Int
    ) async throws -> [BrewNetProfile] {
        // ä½¿ç”¨ PostgreSQL å…¨æ–‡æœç´¢
        let response = try await supabaseService.client
            .from("user_features")
            .select("""
                user_id,
                location,
                industry,
                skills,
                career_stage
            """)
            .textSearch("searchable_text_tsv", query: query, config: "english")
            .limit(limit)
            .execute()
        
        // è§£æå¹¶è·å–å®Œæ•´ profile
        // ... å®ç°ç»†èŠ‚
        return []
    }
    
    /// æŒ‰å­¦æ ¡æœç´¢
    private func searchBySchool(
        school: String,
        limit: Int
    ) async throws -> [BrewNetProfile] {
        // SQL: WHERE professional_background->'educations' @> '[{"school_name": "Stanford"}]'
        return []
    }
    
    /// æŒ‰å…¬å¸æœç´¢
    private func searchByCompany(
        company: String,
        limit: Int
    ) async throws -> [BrewNetProfile] {
        // SQL: WHERE professional_background->>'current_company' ILIKE '%Google%'
        return []
    }
}
```

---

## Phase 2: NLP å±‚å‡çº§

### 2.1 æŸ¥è¯¢è§£æå™¨

**æ–°æ–‡ä»¶**: `BrewNet/QueryParser.swift`

```swift
import Foundation
import NaturalLanguage

/// ç»“æ„åŒ–æŸ¥è¯¢æ„å›¾
struct ParsedQuery {
    let rawText: String
    let tokens: [String]
    let entities: QueryEntities
    let modifiers: QueryModifiers
}

/// å®ä½“è¯†åˆ«ç»“æœ
struct QueryEntities {
    var companies: [String] = []
    var roles: [String] = []
    var schools: [String] = []
    var skills: [String] = []
    var industries: [String] = []
    var numbers: [Double] = []
}

/// æŸ¥è¯¢ä¿®é¥°ç¬¦
struct QueryModifiers {
    var negations: [String] = []  // "not", "except"
    var emphasis: [String] = []   // "must", "only"
    var fuzzy: [String] = []      // "around", "about"
}

class QueryParser {
    
    // MARK: - é¢†åŸŸè¯å…¸
    
    private let companyDictionary: Set<String> = [
        "google", "facebook", "meta", "amazon", "apple", "microsoft",
        "netflix", "uber", "airbnb", "stripe", "openai",
        "mckinsey", "bain", "bcg",  // MBB
        "goldman", "morgan stanley", "jpmorgan"  // Finance
    ]
    
    private let roleDictionary: Set<String> = [
        "product manager", "pm", "engineer", "swe", "software engineer",
        "designer", "data scientist", "ml engineer", "founder", "ceo"
    ]
    
    private let schoolDictionary: Set<String> = [
        "stanford", "harvard", "mit", "yale", "princeton",
        "berkeley", "caltech", "cornell", "columbia", "penn"
    ]
    
    private let skillDictionary: Set<String> = [
        "python", "java", "javascript", "react", "ml", "ai",
        "leadership", "marketing", "sales", "design"
    ]
    
    // MARK: - åŒä¹‰è¯æ˜ å°„
    
    private let synonymMap: [String: [String]] = [
        "pm": ["product manager", "program manager"],
        "swe": ["software engineer", "developer", "engineer"],
        "ml": ["machine learning", "ai", "artificial intelligence"],
        "fb": ["facebook", "meta"],
        "linkedin": ["linkedin", "in"],
        "founder": ["entrepreneur", "startup owner", "ceo"],
        "mentor": ["coach", "advisor", "guide"],
        "alumni": ["alum", "graduate"]
    ]
    
    // MARK: - æ¦‚å¿µæ ‡ç­¾æ˜ å°„
    
    private let conceptTagMap: [String: [String]] = [
        "top tech": ["google", "facebook", "meta", "amazon", "apple", "microsoft"],
        "faang": ["facebook", "meta", "amazon", "apple", "netflix", "google"],
        "mbb": ["mckinsey", "bain", "bcg"],
        "ivy league": ["harvard", "yale", "princeton", "columbia", "penn", "brown", "dartmouth", "cornell"],
        "big tech": ["google", "facebook", "meta", "amazon", "apple", "microsoft", "netflix", "uber"]
    ]
    
    // MARK: - è§£æä¸»å‡½æ•°
    
    func parse(_ query: String) -> ParsedQuery {
        let normalized = query.lowercased()
        
        // 1. åŸºç¡€åˆ†è¯
        let tokens = tokenize(normalized)
        
        // 2. å®ä½“è¯†åˆ«
        let entities = extractEntities(from: normalized, tokens: tokens)
        
        // 3. è¯†åˆ«ä¿®é¥°ç¬¦
        let modifiers = extractModifiers(from: tokens)
        
        // 4. åŒä¹‰è¯æ‰©å±•
        let expandedTokens = expandSynonyms(tokens: tokens)
        
        // 5. æ¦‚å¿µæ ‡ç­¾æ‰©å±•
        let conceptExpanded = expandConcepts(tokens: expandedTokens)
        
        return ParsedQuery(
            rawText: normalized,
            tokens: conceptExpanded,
            entities: entities,
            modifiers: modifiers
        )
    }
    
    // MARK: - å®ä½“è¯†åˆ«
    
    private func extractEntities(
        from text: String,
        tokens: [String]
    ) -> QueryEntities {
        var entities = QueryEntities()
        
        // ä½¿ç”¨ NLTagger è¿›è¡Œå‘½åå®ä½“è¯†åˆ«
        let tagger = NLTagger(tagSchemes: [.nameType])
        tagger.string = text
        
        let options: NLTagger.Options = [.omitPunctuation, .omitWhitespace, .joinNames]
        tagger.enumerateTags(in: text.startIndex..<text.endIndex, unit: .word, scheme: .nameType, options: options) { tag, tokenRange in
            if let tag = tag {
                let entity = String(text[tokenRange])
                
                switch tag {
                case .organizationName:
                    entities.companies.append(entity)
                default:
                    break
                }
            }
            return true
        }
        
        // ä½¿ç”¨è¯å…¸åŒ¹é…ï¼ˆæ›´å‡†ç¡®ï¼‰
        for token in tokens {
            if companyDictionary.contains(token) {
                entities.companies.append(token)
            }
            if roleDictionary.contains(token) {
                entities.roles.append(token)
            }
            if schoolDictionary.contains(token) {
                entities.schools.append(token)
            }
            if skillDictionary.contains(token) {
                entities.skills.append(token)
            }
        }
        
        // å¤šè¯çŸ­è¯­åŒ¹é…
        entities.companies.append(contentsOf: matchPhrases(in: text, dictionary: companyDictionary))
        entities.roles.append(contentsOf: matchPhrases(in: text, dictionary: roleDictionary))
        entities.schools.append(contentsOf: matchPhrases(in: text, dictionary: schoolDictionary))
        
        // æå–æ•°å­—
        entities.numbers = extractNumbers(from: text)
        
        return entities
    }
    
    private func matchPhrases(in text: String, dictionary: Set<String>) -> [String] {
        var matches: [String] = []
        for phrase in dictionary {
            if phrase.contains(" ") && text.contains(phrase) {
                matches.append(phrase)
            }
        }
        return matches
    }
    
    // MARK: - ä¿®é¥°ç¬¦è¯†åˆ«
    
    private func extractModifiers(from tokens: [String]) -> QueryModifiers {
        var modifiers = QueryModifiers()
        
        for (index, token) in tokens.enumerated() {
            if ["not", "no", "except", "without"].contains(token) {
                // è·å–å¦å®šè¯åé¢çš„è¯
                if index + 1 < tokens.count {
                    modifiers.negations.append(tokens[index + 1])
                }
            }
            
            if ["must", "only", "require", "need"].contains(token) {
                if index + 1 < tokens.count {
                    modifiers.emphasis.append(tokens[index + 1])
                }
            }
            
            if ["around", "about", "approximately", "~"].contains(token) {
                if index + 1 < tokens.count {
                    modifiers.fuzzy.append(tokens[index + 1])
                }
            }
        }
        
        return modifiers
    }
    
    // MARK: - åŒä¹‰è¯æ‰©å±•
    
    private func expandSynonyms(tokens: [String]) -> [String] {
        var expanded = tokens
        
        for token in tokens {
            if let synonyms = synonymMap[token] {
                expanded.append(contentsOf: synonyms)
            }
        }
        
        return expanded
    }
    
    // MARK: - æ¦‚å¿µæ ‡ç­¾æ‰©å±•
    
    private func expandConcepts(tokens: [String]) -> [String] {
        var expanded = tokens
        
        // æ£€æµ‹æ¦‚å¿µçŸ­è¯­
        let joinedText = tokens.joined(separator: " ")
        
        for (concept, expansions) in conceptTagMap {
            if joinedText.contains(concept) {
                expanded.append(contentsOf: expansions)
                print("ğŸ·ï¸ Expanded concept: \(concept) â†’ \(expansions.joined(separator: ", "))")
            }
        }
        
        return expanded
    }
    
    // MARK: - è¾…åŠ©å‡½æ•°
    
    private func tokenize(_ text: String) -> [String] {
        text
            .lowercased()
            .components(separatedBy: CharacterSet.alphanumerics.inverted)
            .filter { !$0.isEmpty && $0.count > 1 }
    }
    
    private func extractNumbers(from text: String) -> [Double] {
        let components = text.components(separatedBy: CharacterSet(charactersIn: "0123456789").inverted)
        return components.compactMap { Double($0) }
    }
}
```

### 2.2 ç¼©å†™å¤„ç†å¢å¼º

```swift
extension QueryParser {
    /// æ‰©å±•çš„ç¼©å†™æ˜ å°„
    private static let abbreviationMap: [String: [String]] = [
        // èŒä½ç¼©å†™
        "pm": ["product manager", "program manager", "project manager"],
        "swe": ["software engineer", "software developer"],
        "ds": ["data scientist", "data science"],
        "ml": ["machine learning", "ml engineer"],
        "ui": ["user interface"],
        "ux": ["user experience"],
        "qa": ["quality assurance"],
        "hr": ["human resources"],
        "ceo": ["chief executive officer", "founder"],
        "cto": ["chief technology officer"],
        "cfo": ["chief financial officer"],
        
        // å…¬å¸ç¼©å†™
        "fb": ["facebook", "meta"],
        "msft": ["microsoft"],
        "amzn": ["amazon"],
        "googl": ["google", "alphabet"],
        
        // å­¦ä½ç¼©å†™
        "bs": ["bachelor", "bachelor's"],
        "ms": ["master", "master's"],
        "mba": ["master of business administration"],
        "phd": ["doctor of philosophy", "doctorate"],
        
        // æŠ€èƒ½ç¼©å†™
        "ai": ["artificial intelligence"],
        "nlp": ["natural language processing"],
        "cv": ["computer vision"],
        "ml": ["machine learning"],
        "dl": ["deep learning"]
    ]
}
```

---

## Phase 3: ç‰¹å¾å·¥ç¨‹å‡çº§

### 3.1 åˆ†åŒºåŠ æƒæœç´¢

**æ–°æ–‡ä»¶**: `BrewNet/FieldAwareScoring.swift`

```swift
import Foundation

/// å­—æ®µæƒé‡é…ç½®
enum FieldZone {
    case zoneA  // é«˜æƒ: Current Title, Company, Top Skills
    case zoneB  // ä¸­æƒ: Bio, Past Experience, School
    case zoneC  // ä½æƒ: Hobbies, Interests
    
    var weight: Double {
        switch self {
        case .zoneA: return 3.0
        case .zoneB: return 1.5
        case .zoneC: return 0.5
        }
    }
}

/// åˆ†åŒºç´¢å¼•æ–‡æœ¬
struct ZonedSearchableText {
    let zoneA: String  // é«˜æƒæ–‡æœ¬
    let zoneB: String  // ä¸­æƒæ–‡æœ¬
    let zoneC: String  // ä½æƒæ–‡æœ¬
    
    /// æ„å»ºåˆ†åŒºæ–‡æœ¬
    static func from(profile: BrewNetProfile) -> ZonedSearchableText {
        // Zone A: å½“å‰èŒä½ã€å…¬å¸ã€æ ¸å¿ƒæŠ€èƒ½
        var zoneA = [
            profile.professionalBackground.jobTitle ?? "",
            profile.professionalBackground.currentCompany ?? "",
            profile.professionalBackground.industry ?? ""
        ]
        zoneA.append(contentsOf: Array(profile.professionalBackground.skills.prefix(3)))
        
        // Zone B: ç®€ä»‹ã€è¿‡å¾€ç»å†ã€æ•™è‚²
        var zoneB = [
            profile.coreIdentity.bio ?? "",
            profile.coreIdentity.location ?? ""
        ]
        if let educations = profile.professionalBackground.educations {
            zoneB.append(contentsOf: educations.map { $0.schoolName })
        }
        for exp in profile.professionalBackground.workExperiences.prefix(3) {
            zoneB.append(exp.companyName)
            zoneB.append(exp.position ?? "")
        }
        
        // Zone C: çˆ±å¥½ã€å…´è¶£
        var zoneC = profile.personalitySocial.hobbies
        zoneC.append(contentsOf: profile.personalitySocial.valuesTags)
        
        return ZonedSearchableText(
            zoneA: zoneA.joined(separator: " ").lowercased(),
            zoneB: zoneB.joined(separator: " ").lowercased(),
            zoneC: zoneC.joined(separator: " ").lowercased()
        )
    }
}

/// å­—æ®µæ„ŸçŸ¥è¯„åˆ†
class FieldAwareScoring {
    
    /// è®¡ç®—å­—æ®µæ„ŸçŸ¥åˆ†æ•°
    func computeScore(
        profile: BrewNetProfile,
        tokens: [String],
        zonedText: ZonedSearchableText
    ) -> Double {
        var score: Double = 0.0
        
        for token in tokens {
            if token.count < 2 { continue }
            
            // åœ¨ä¸åŒåŒºåŸŸæœç´¢ï¼Œåº”ç”¨ä¸åŒæƒé‡
            if zonedText.zoneA.contains(token) {
                score += FieldZone.zoneA.weight
                print("  âœ“ '\(token)' in Zone A (Ã—3.0)")
            } else if zonedText.zoneB.contains(token) {
                score += FieldZone.zoneB.weight
                print("  âœ“ '\(token)' in Zone B (Ã—1.5)")
            } else if zonedText.zoneC.contains(token) {
                score += FieldZone.zoneC.weight
                print("  âœ“ '\(token)' in Zone C (Ã—0.5)")
            }
        }
        
        return score
    }
}
```

### 3.2 æ¦‚å¿µæ ‡ç­¾ç³»ç»Ÿ

**æ–°æ–‡ä»¶**: `BrewNet/ConceptTagger.swift`

```swift
import Foundation

/// æ¦‚å¿µæ ‡ç­¾
enum ConceptTag: String, CaseIterable {
    case bigTech = "tag_big_tech"
    case startup = "tag_startup"
    case ivyLeague = "tag_ivy_league"
    case topMBA = "tag_top_mba"
    case faang = "tag_faang"
    case mbb = "tag_mbb"
    case finance = "tag_finance"
    case unicorn = "tag_unicorn"
}

class ConceptTagger {
    
    // MARK: - å…¬å¸åˆ†ç±»
    
    private static let bigTechCompanies: Set<String> = [
        "google", "alphabet", "facebook", "meta", "amazon", "apple",
        "microsoft", "netflix", "tesla", "nvidia"
    ]
    
    private static let faangCompanies: Set<String> = [
        "facebook", "meta", "apple", "amazon", "netflix", "google", "alphabet"
    ]
    
    private static let mbbCompanies: Set<String> = [
        "mckinsey", "bain", "bcg", "boston consulting"
    ]
    
    private static let unicornCompanies: Set<String> = [
        "stripe", "spacex", "databricks", "canva", "figma", "notion"
    ]
    
    // MARK: - å­¦æ ¡åˆ†ç±»
    
    private static let ivyLeagueSchools: Set<String> = [
        "harvard", "yale", "princeton", "columbia", "penn",
        "brown", "dartmouth", "cornell"
    ]
    
    private static let topMBASchools: Set<String> = [
        "harvard", "stanford", "wharton", "penn", "mit", "kellogg",
        "booth", "chicago", "columbia", "berkeley", "haas"
    ]
    
    // MARK: - æ ‡ç­¾ç”Ÿæˆ
    
    /// ä¸ºç”¨æˆ· Profile ç”Ÿæˆæ¦‚å¿µæ ‡ç­¾
    static func generateTags(for profile: BrewNetProfile) -> Set<ConceptTag> {
        var tags: Set<ConceptTag> = []
        
        // å…¬å¸æ ‡ç­¾
        if let company = profile.professionalBackground.currentCompany?.lowercased() {
            if bigTechCompanies.contains(where: { company.contains($0) }) {
                tags.insert(.bigTech)
            }
            if faangCompanies.contains(where: { company.contains($0) }) {
                tags.insert(.faang)
            }
            if mbbCompanies.contains(where: { company.contains($0) }) {
                tags.insert(.mbb)
                tags.insert(.finance)
            }
            if unicornCompanies.contains(where: { company.contains($0) }) {
                tags.insert(.unicorn)
            }
            if company.contains("startup") || profile.professionalBackground.careerStage == .founder {
                tags.insert(.startup)
            }
        }
        
        // å­¦æ ¡æ ‡ç­¾
        if let educations = profile.professionalBackground.educations {
            for education in educations {
                let school = education.schoolName.lowercased()
                if ivyLeagueSchools.contains(where: { school.contains($0) }) {
                    tags.insert(.ivyLeague)
                }
                if topMBASchools.contains(where: { school.contains($0) }) && 
                   education.degree == .mba {
                    tags.insert(.topMBA)
                }
            }
        }
        
        return tags
    }
    
    /// æŸ¥è¯¢ä¸­çš„æ¦‚å¿µæ ‡ç­¾æ˜ å°„
    static func mapQueryToConcepts(query: String) -> [ConceptTag] {
        var concepts: [ConceptTag] = []
        let lowercased = query.lowercased()
        
        if lowercased.contains("top tech") || lowercased.contains("big tech") {
            concepts.append(.bigTech)
        }
        if lowercased.contains("faang") {
            concepts.append(.faang)
        }
        if lowercased.contains("mbb") {
            concepts.append(.mbb)
        }
        if lowercased.contains("ivy league") || lowercased.contains("ivy") {
            concepts.append(.ivyLeague)
        }
        if lowercased.contains("top mba") || lowercased.contains("m7") {
            concepts.append(.topMBA)
        }
        if lowercased.contains("startup") || lowercased.contains("founder") {
            concepts.append(.startup)
        }
        if lowercased.contains("unicorn") {
            concepts.append(.unicorn)
        }
        
        return concepts
    }
}

// MARK: - Profile æ‰©å±•

extension BrewNetProfile {
    /// è·å–æ¦‚å¿µæ ‡ç­¾
    var conceptTags: Set<ConceptTag> {
        ConceptTagger.generateTags(for: self)
    }
}
```

---

## Phase 4: è¯„åˆ†ç®—æ³•å‡çº§

### 4.1 BM25 ç®—æ³•

**æ–°æ–‡ä»¶**: `BrewNet/BM25Scorer.swift`

```swift
import Foundation

/// BM25 ç®—æ³•å®ç°
class BM25Scorer {
    
    // BM25 å‚æ•°
    private let k1: Double = 1.5  // è¯é¢‘é¥±å’Œå‚æ•°
    private let b: Double = 0.75   // é•¿åº¦å½’ä¸€åŒ–å‚æ•°
    
    /// æ–‡æ¡£é›†åˆçš„è¯é¢‘ç»Ÿè®¡
    private var documentFrequency: [String: Int] = [:]
    private var totalDocuments: Int = 0
    private var averageDocumentLength: Double = 0.0
    
    /// åˆå§‹åŒ–ï¼ˆéœ€è¦éå†æ‰€æœ‰æ–‡æ¡£ç»Ÿè®¡ï¼‰
    func initialize(profiles: [BrewNetProfile]) {
        totalDocuments = profiles.count
        var totalLength: Double = 0.0
        var df: [String: Set<String>] = [:]  // term -> set of doc ids
        
        for profile in profiles {
            let text = aggregatedSearchableText(for: profile)
            let tokens = tokenize(text)
            totalLength += Double(tokens.count)
            
            // ç»Ÿè®¡æ–‡æ¡£é¢‘ç‡
            let uniqueTokens = Set(tokens)
            for token in uniqueTokens {
                if df[token] == nil {
                    df[token] = Set()
                }
                df[token]?.insert(profile.userId)
            }
        }
        
        averageDocumentLength = totalLength / Double(totalDocuments)
        documentFrequency = df.mapValues { $0.count }
        
        print("ğŸ“Š BM25 initialized:")
        print("  - Total documents: \(totalDocuments)")
        print("  - Avg doc length: \(averageDocumentLength)")
        print("  - Vocabulary size: \(documentFrequency.count)")
    }
    
    /// è®¡ç®— BM25 åˆ†æ•°
    func score(
        profile: BrewNetProfile,
        queryTokens: [String]
    ) -> Double {
        let docText = aggregatedSearchableText(for: profile)
        let docTokens = tokenize(docText)
        let docLength = Double(docTokens.count)
        
        // è®¡ç®—è¯é¢‘ TF
        var termFrequency: [String: Int] = [:]
        for token in docTokens {
            termFrequency[token, default: 0] += 1
        }
        
        var score: Double = 0.0
        
        for queryToken in Set(queryTokens) {
            let tf = Double(termFrequency[queryToken] ?? 0)
            let df = Double(documentFrequency[queryToken] ?? 1)
            
            // IDF è®¡ç®—
            let idf = log((Double(totalDocuments) - df + 0.5) / (df + 0.5) + 1.0)
            
            // BM25 å…¬å¼
            let numerator = tf * (k1 + 1.0)
            let denominator = tf + k1 * (1.0 - b + b * (docLength / averageDocumentLength))
            
            score += idf * (numerator / denominator)
        }
        
        return score
    }
    
    private func aggregatedSearchableText(for profile: BrewNetProfile) -> String {
        // å¤ç”¨åŸæœ‰é€»è¾‘
        var parts: [String] = []
        parts.append(profile.coreIdentity.name)
        parts.append(profile.coreIdentity.bio ?? "")
        parts.append(profile.professionalBackground.currentCompany ?? "")
        parts.append(profile.professionalBackground.jobTitle ?? "")
        parts.append(contentsOf: profile.professionalBackground.skills)
        return parts.joined(separator: " ").lowercased()
    }
    
    private func tokenize(_ text: String) -> [String] {
        text.components(separatedBy: CharacterSet.alphanumerics.inverted)
            .filter { !$0.isEmpty && $0.count > 1 }
    }
}
```

### 4.2 è½¯åŒ¹é…é€»è¾‘

**æ–°æ–‡ä»¶**: `BrewNet/SoftMatching.swift`

```swift
import Foundation

class SoftMatching {
    
    /// é«˜æ–¯è¡°å‡å‡½æ•°ï¼ˆç”¨äºå¹´é™åŒ¹é…ï¼‰
    static func gaussianDecay(
        actual: Double,
        target: Double,
        sigma: Double = 1.0
    ) -> Double {
        let exponent = -pow(actual - target, 2) / (2 * pow(sigma, 2))
        return exp(exponent)
    }
    
    /// è½¯å¹´é™åŒ¹é…
    static func softExperienceMatch(
        profile: BrewNetProfile,
        targetYears: [Double]
    ) -> Double {
        guard let actual = profile.professionalBackground.yearsOfExperience else {
            return 0.0
        }
        
        var maxScore: Double = 0.0
        
        for target in targetYears {
            let score = gaussianDecay(actual: actual, target: target, sigma: 1.5)
            maxScore = max(maxScore, score)
        }
        
        // å½’ä¸€åŒ–åˆ° [0, 2.0] åŒºé—´ï¼ˆåŒ¹é…åŸæœ‰ +2.0 çš„é€»è¾‘ï¼‰
        return maxScore * 2.0
    }
    
    /// æ¨¡ç³Šå­—ç¬¦ä¸²åŒ¹é…ï¼ˆLevenshtein è·ç¦»ï¼‰
    static func fuzzyStringMatch(
        string1: String,
        string2: String,
        threshold: Int = 2
    ) -> Bool {
        let distance = levenshteinDistance(string1, string2)
        return distance <= threshold
    }
    
    /// Levenshtein è·ç¦»è®¡ç®—
    private static func levenshteinDistance(_ s1: String, _ s2: String) -> Int {
        let m = s1.count
        let n = s2.count
        
        var dp = Array(repeating: Array(repeating: 0, count: n + 1), count: m + 1)
        
        for i in 0...m {
            dp[i][0] = i
        }
        for j in 0...n {
            dp[0][j] = j
        }
        
        let s1Array = Array(s1)
        let s2Array = Array(s2)
        
        for i in 1...m {
            for j in 1...n {
                if s1Array[i-1] == s2Array[j-1] {
                    dp[i][j] = dp[i-1][j-1]
                } else {
                    dp[i][j] = min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1]) + 1
                }
            }
        }
        
        return dp[m][n]
    }
}
```

### 4.3 åŠ¨æ€æƒé‡è°ƒæ•´

```swift
/// ä¸Šä¸‹æ–‡æ„ŸçŸ¥æƒé‡
class ContextAwareWeighting {
    
    /// æ ¹æ®æŸ¥è¯¢å¤æ‚åº¦åŠ¨æ€è°ƒæ•´æƒé‡
    static func adjustWeights(
        for query: String,
        baseRecommendationWeight: Double = 0.3,
        baseTextWeight: Double = 0.7
    ) -> (recommendation: Double, text: Double) {
        
        let tokens = query.lowercased()
            .components(separatedBy: CharacterSet.alphanumerics.inverted)
            .filter { !$0.isEmpty }
        
        let queryLength = tokens.count
        let hasNumbers = tokens.contains(where: { Double($0) != nil })
        let hasSpecificTerms = tokens.contains(where: { 
            ["alumni", "founder", "mentor", "years"].contains($0) 
        })
        
        var recWeight = baseRecommendationWeight
        var textWeight = baseTextWeight
        
        // æŸ¥è¯¢å¾ˆçŸ­ï¼ˆâ‰¤2è¯ï¼‰ï¼šæ›´ä¾èµ–æ¨èç³»ç»Ÿ
        if queryLength <= 2 {
            recWeight = 0.5
            textWeight = 0.5
        }
        
        // æŸ¥è¯¢å¾ˆé•¿ä¸”å…·ä½“ï¼ˆâ‰¥6è¯ + æ•°å­—ï¼‰ï¼šæ›´ä¾èµ–æ–‡æœ¬åŒ¹é…
        if queryLength >= 6 && hasNumbers {
            recWeight = 0.2
            textWeight = 0.8
        }
        
        // åŒ…å«ç‰¹å®šæœ¯è¯­ï¼šæé«˜æ–‡æœ¬æƒé‡
        if hasSpecificTerms {
            textWeight += 0.1
            recWeight -= 0.1
        }
        
        // å½’ä¸€åŒ–
        let total = recWeight + textWeight
        recWeight /= total
        textWeight /= total
        
        print("âš–ï¸ Dynamic weights: Rec=\(String(format: "%.1f%%", recWeight*100)), Text=\(String(format: "%.1f%%", textWeight*100))")
        
        return (recWeight, textWeight)
    }
}
```

---

## å®æ–½è®¡åˆ’

### æ—¶é—´çº¿

| é˜¶æ®µ | ä»»åŠ¡ | é¢„è®¡æ—¶é—´ | ä¼˜å…ˆçº§ |
|-----|------|---------|--------|
| **Phase 1** | æ•°æ®åº“ç´¢å¼•å‡çº§ | 1å‘¨ | ğŸ”´ Critical |
| **Phase 1** | å¬å›æœåŠ¡å®ç° | 1å‘¨ | ğŸ”´ Critical |
| **Phase 2** | æŸ¥è¯¢è§£æå™¨ | 1å‘¨ | ğŸ”´ Critical |
| **Phase 2** | åŒä¹‰è¯/ç¼©å†™ | 3å¤© | ğŸŸ¡ High |
| **Phase 3** | åˆ†åŒºåŠ æƒ | 3å¤© | ğŸŸ¡ High |
| **Phase 3** | æ¦‚å¿µæ ‡ç­¾ | 1å‘¨ | ğŸŸ¡ High |
| **Phase 4** | BM25å®ç° | 1å‘¨ | ğŸŸ¢ Medium |
| **Phase 4** | è½¯åŒ¹é… | 3å¤© | ğŸŸ¢ Medium |
| **Phase 4** | åŠ¨æ€æƒé‡ | 2å¤© | ğŸŸ¢ Medium |
| **Testing** | é›†æˆæµ‹è¯• | 1å‘¨ | ğŸ”´ Critical |
| **Optimization** | æ€§èƒ½ä¼˜åŒ– | 1å‘¨ | ğŸŸ¡ High |

**æ€»è®¡**: çº¦ 8-10 å‘¨

### é‡Œç¨‹ç¢‘

- âœ… **Week 2**: æ•°æ®åº“å¬å›èƒ½åŠ›æå‡åˆ° 200+ äºº
- âœ… **Week 4**: åŸºç¡€ NLP è§£æä¸Šçº¿ï¼ˆåŒä¹‰è¯ã€ç¼©å†™ï¼‰
- âœ… **Week 6**: æ¦‚å¿µæ ‡ç­¾ç³»ç»Ÿä¸Šçº¿ï¼ˆ"Top Tech", "Ivy League"ï¼‰
- âœ… **Week 8**: BM25 + è½¯åŒ¹é…ä¸Šçº¿
- âœ… **Week 10**: å…¨é¢æµ‹è¯• + æ€§èƒ½è°ƒä¼˜

---

## é¢„æœŸæ”¶ç›Š

### å¬å›ç‡æå‡

```
åœºæ™¯: "Stanford alumni, PM at Google"

V1.0 (å½“å‰):
  å€™é€‰æ± : 60äºº
  å¬å›: 2äººï¼ˆå¦‚æœæ¨èç³»ç»Ÿæ°å¥½åŒ…å«ï¼‰
  å‡†ç¡®ç‡: ~40%

V2.0 (å‡çº§å):
  å€™é€‰æ± : 500äºº
  å¬å›: 15äººï¼ˆå…¨åº“æœç´¢ï¼‰
  å‡†ç¡®ç‡: ~85%

æå‡: 7.5å€å¬å› + 45% å‡†ç¡®ç‡
```

### è¯­ä¹‰ç†è§£æå‡

```
æŸ¥è¯¢: "Top tech PM with 5 years"

V1.0:
  ç†è§£: ["top", "tech", "pm", "5", "years"]
  åŒ¹é…: åªåŒ¹é…åˆ° "PM" å­—æ ·çš„äºº

V2.0:
  ç†è§£: {
    concept: "top tech" â†’ [Google, Meta, Amazon, ...]
    role: "PM" â†’ "Product Manager"
    experience: 5 Â± 1.5 years (é«˜æ–¯è¡°å‡)
  }
  åŒ¹é…: æ‰€æœ‰ FAANG PMï¼Œ4-6.5å¹´ç»éªŒ
```

### å“åº”æ—¶é—´ä¼˜åŒ–

```
V1.0:
  æ¨èç³»ç»Ÿ: 500ms
  æœ¬åœ°åŒ¹é…: 300ms
  æ€»è®¡: 800ms

V2.0:
  æ•°æ®åº“å¬å›: 300ms (ç´¢å¼•åŠ é€Ÿ)
  NLPè§£æ: 50ms
  ç²¾æ’: 200ms
  æ€»è®¡: 550ms

æå‡: -31% å“åº”æ—¶é—´
```

---

## é£é™©ä¸å¯¹ç­–

### é£é™© 1: æ•°æ®åº“æ€§èƒ½

**é£é™©**: å…¨åº“æœç´¢å¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™  
**å¯¹ç­–**:
- ä½¿ç”¨ PostgreSQL å…¨æ–‡ç´¢å¼•ï¼ˆGINï¼‰
- æ·»åŠ æŸ¥è¯¢ç¼“å­˜
- é™åˆ¶å¬å›ä¸Šé™ï¼ˆ500äººï¼‰

### é£é™© 2: å¤æ‚åº¦æå‡

**é£é™©**: ä»£ç å¤æ‚åº¦å¤§å¹…æå‡  
**å¯¹ç­–**:
- æ¨¡å—åŒ–è®¾è®¡ï¼ˆç‹¬ç«‹æ–‡ä»¶ï¼‰
- å……åˆ†çš„å•å…ƒæµ‹è¯•
- è¯¦ç»†çš„æ–‡æ¡£

### é£é™© 3: å‡†ç¡®ç‡æ³¢åŠ¨

**é£é™©**: æ–°ç®—æ³•å¯èƒ½åœ¨æŸäº›åœºæ™¯è¡¨ç°ä¸å¦‚é¢„æœŸ  
**å¯¹ç­–**:
- A/B æµ‹è¯•
- é€æ­¥ç°åº¦å‘å¸ƒ
- æ”¶é›†ç”¨æˆ·åé¦ˆ

---

## ç›‘æ§æŒ‡æ ‡

### å…³é”®æŒ‡æ ‡

| æŒ‡æ ‡ | å½“å‰ | ç›®æ ‡ | ç›‘æ§æ–¹å¼ |
|-----|------|------|---------|
| å¬å›æ± å¤§å° | 60 | 200-500 | æ—¥å¿— |
| Top 5 ç‚¹å‡»ç‡ | ? | >60% | Analytics |
| é‚€è¯·è½¬åŒ–ç‡ | ? | >20% | Database |
| å“åº”æ—¶é—´ P50 | 800ms | <600ms | APM |
| å“åº”æ—¶é—´ P95 | 1500ms | <1000ms | APM |
| æŸ¥è¯¢å¤±è´¥ç‡ | <1% | <0.5% | Error Log |

---

## åç»­ä¼˜åŒ–æ–¹å‘

### V3.0 å±•æœ›

1. **æ·±åº¦å­¦ä¹ æ¨¡å‹**
   - BERT-based è¯­ä¹‰åŒ¹é…
   - ç«¯åˆ°ç«¯å­¦ä¹ æ’åº

2. **ä¸ªæ€§åŒ–**
   - ç”¨æˆ·å†å²è¡Œä¸ºå»ºæ¨¡
   - ååŒè¿‡æ»¤

3. **å¤šæ¨¡æ€**
   - å›¾ç‰‡ç†è§£ï¼ˆå·¥ä½œç…§ã€ç”Ÿæ´»ç…§ï¼‰
   - è§†é¢‘ç®€ä»‹åˆ†æ

4. **å®æ—¶æ›´æ–°**
   - ç”¨æˆ·ä¸Šçº¿ç«‹å³å¯æœ
   - å¢é‡ç´¢å¼•æ›´æ–°

---

## æ€»ç»“

è¿™æ¬¡å‡çº§å°†ä»æ ¹æœ¬ä¸Šè§£å†³ Headhunting çš„ä¸¤å¤§ç“¶é¢ˆï¼š

1. **å¬å›æ± æ‰©å¤§ 8å€**ï¼šä» 60äºº â†’ 500äºº
2. **è¯­ä¹‰ç†è§£è´¨çš„é£è·ƒ**ï¼šä»å…³é”®è¯ â†’ æ„å›¾ç†è§£

é¢„è®¡æ•´ä½“å‡†ç¡®ç‡æå‡ **45%**ï¼Œå“åº”æ—¶é—´é™ä½ **31%**ã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬**: 2.0 Plan  
**åˆ›å»ºæ—¥æœŸ**: 2024-11-21  
**çŠ¶æ€**: ğŸš§ å¾…å®æ–½  
**è´Ÿè´£äºº**: BrewNet Team Heady

